# -*- coding: utf-8 -*-
"""Student performance analyzer

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kTzDDUscB4TaQ5bfIikjAiyDbYOkFYTZ
"""



        # -*- coding: utf-8 -*-
"""Student performance analyzer (with ML Prediction)

Automatically generated by Colab.
"""

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
# NEW IMPORTS FOR ML
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report
import io

st.set_page_config(
    page_title="Student Performance Analyzer",
    page_icon="üìö",
    layout="wide",
    initial_sidebar_state="expanded"
)

# FIXED CSS
st.markdown("""
    <style>
    .main {
      padding-top: 2rem;
    }
    .stTabs [data-baseweb="tab-list"]{
      gap:24px;
    }
    .stTabs [data-baseweb="tab"] {
      height:50px;
      padding-left:20px;
      padding-right:20px;
    }
    </style>
""", unsafe_allow_html=True)

def categorize_performance(grade):
    """Categorize student performance into 4 levels"""
    if grade < 10:
        return 'Fail'
    elif grade < 14:
        return 'Pass'
    elif grade < 17:
        return 'Good'
    else:
        return 'Excellent'

@st.cache_data
def load_data():
    """
    load the student performance dataset from UCI repository
    Returns:
        pd.DataFrame:Loaded and preprocessed dataset
    """
    url = "https://raw.githubusercontent.com/arunk13/MSDA-Assignments/master/IS607Fall2015/Assignment3/student-mat.csv"
    df = pd.read_csv(url, sep=';')
    df['average_grade'] = (df['G1'] + df['G2'] + df['G3']) / 3
    df['performance_category'] = df['G3'].apply(categorize_performance)
    return df

def calculate_overall_stats(df):
    """Calculate overall grade statistics"""
    return {
        'mean': df['G3'].mean(),
        'median': df['G3'].median(),
        'std': df['G3'].std(),
        'min': df['G3'].min(),
        'max': df['G3'].max(),
        'pass_rate': (df['G3'] >= 10).sum() / len(df) * 100,
        'fail_rate': (df['G3'] < 10).sum() / len(df) * 100
    }

def analyze_by_category(df, category_col, value_col='G3'):
    """Analyze performance by a specific category"""
    return df.groupby(category_col)[value_col].agg(['mean', 'median', 'count', 'std']).round(2)

def get_correlation_data(df):
    """Get correlation data for key numerical features"""
    numerical_cols = ['age', 'Medu', 'Fedu', 'studytime', 'failures', 'absences', 'G1', 'G2']
    correlations = df[numerical_cols + ['G3']].corr()['G3'].sort_values(ascending=False)
    return correlations

def plot_grade_distribution(df):
    """Create histogram of final grade distribution"""
    fig, ax = plt.subplots()
    ax.hist(df['G3'], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    ax.axvline(df['G3'].mean(), color='red', linestyle='--', linewidth=2,
               label=f'Mean: {df["G3"].mean():.2f}')
    ax.set_xlabel('Final Grade (G3)', fontsize=12)
    ax.set_ylabel('Number of Students', fontsize=12)
    ax.set_title('Distribution of Final Grades', fontsize=14, fontweight='bold')
    ax.legend()
    ax.grid(axis='y', alpha=0.3)
    return fig

def plot_performance_pie(df):
    """Create pie chart of performance categories"""
    fig, ax = plt.subplots(figsize=(8, 8))
    category_counts = df['performance_category'].value_counts()
    # Sort categories for consistent plotting
    sorted_index = ['Fail', 'Pass', 'Good', 'Excellent']
    category_counts = category_counts.reindex(sorted_index, fill_value=0)
    colors = ['#ff6b6b', '#ffd93d', '#6bcf7f', '#4d96ff']
    ax.pie(category_counts, labels=category_counts.index, autopct='%1.1f%%',
           colors=colors, startangle=90, textprops={'fontsize': 11})
    ax.set_title('Performance Category Distribution', fontsize=14, fontweight='bold')
    return fig

def plot_study_time_impact(df):
    """Create bar chart showing study time impact on grades"""
    fig, ax = plt.subplots(figsize=(10, 6))
    study_labels = ['<2h', '2-5h', '5-10h', '>10h']
    study_means = df.groupby('studytime')['G3'].mean()
    # Ensure all 4 categories are present
    study_means = study_means.reindex(range(1, 5), fill_value=0)

    bars = ax.bar(study_labels, study_means,
                  color=['#ff6b6b', '#ffd93d', '#6bcf7f', '#4d96ff'],
                  edgecolor='black', alpha=0.8)
    ax.set_xlabel('Weekly Study Time', fontsize=12)
    ax.set_ylabel('Average Final Grade', fontsize=12)
    ax.set_title('Study Time Impact on Performance', fontsize=14, fontweight='bold')
    ax.set_ylim(0, 20)
    for bar in bars:
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2., height,
               f'{height:.1f}', ha='center', va='bottom', fontsize=10)
    return fig

def plot_gender_comparison(df):
    """Create bar chart comparing gender performance"""
    fig, ax = plt.subplots(figsize=(8, 6))
    gender_data = df.groupby('sex')['G3'].mean()
    bars = ax.bar(gender_data.index, gender_data, # Use index directly
                  color=['#ff99cc', '#6699ff'],
                  edgecolor='black', alpha=0.8)
    ax.set_ylabel('Average Final Grade', fontsize=12)
    ax.set_title('Gender-Based Performance Comparison', fontsize=14, fontweight='bold')
    ax.set_ylim(0, 20)

    for bar in bars:
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2., height,
               f'{height:.1f}', ha='center', va='bottom', fontsize=11)
    return fig

def plot_family_support(df):
    """Create bar chart showing family support impact"""
    fig, ax = plt.subplots(figsize=(8, 6))
    support_data = df.groupby('famsup')['G3'].mean()
    bars = ax.bar(support_data.index, support_data, # Use index directly
                  color=['#ff6b6b', '#6bcf7f'], edgecolor='black', alpha=0.8)
    ax.set_ylabel('Average Final Grade', fontsize=12)
    ax.set_title('Family Support Impact on Performance', fontsize=14, fontweight='bold')
    ax.set_ylim(0, 20)

    for bar in bars:
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2., height,
               f'{height:.1f}', ha='center', va='bottom', fontsize=11)
    return fig

def plot_correlation_heatmap(df):
    """Create correlation heatmap for key features"""
    fig, ax = plt.subplots(figsize=(10, 8))
    key_features = ['G1', 'G2', 'studytime', 'failures', 'absences', 'G3']
    corr_matrix = df[key_features].corr()
    sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm',
                center=0, square=True, linewidths=1, ax=ax, cbar_kws={"shrink": 0.8})
    ax.set_title('Feature Correlation Heatmap', fontsize=14, fontweight='bold')
    return fig

def plot_failures_impact(df):
    """Create bar chart showing impact of past failures"""
    fig, ax = plt.subplots(figsize=(10, 6))
    failures_mean = df.groupby('failures')['G3'].mean()
    bars = ax.bar(failures_mean.index, failures_mean.values,
                  color='coral', edgecolor='black', alpha=0.8)
    ax.set_xlabel('Number of Past Failures', fontsize=12)
    ax.set_ylabel('Average Final Grade', fontsize=12)
    ax.set_title('Impact of Past Failures on Performance', fontsize=14, fontweight='bold')
    ax.set_ylim(0, 20)
    ax.set_xticks(failures_mean.index) # Ensure x-axis ticks are correct

    for bar in bars:
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2., height,
               f'{height:.1f}', ha='center', va='bottom', fontsize=10)
    return fig

@st.cache_data
def perform_ml_analysis(df):
    """
    Performs classification to predict student performance category
    using a Decision Tree Classifier.
    """
    # Features to use (excluding the target and intermediate grades G1, G2)
    features = [
        'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu',
        'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime',
        'failures', 'schoolsup', 'famsup', 'paid', 'activities',
        'nursery', 'higher', 'internet', 'romantic', 'famrel',
        'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences'
    ]
    target = 'performance_category'

    # Prepare data
    df_ml = df[features + [target]].copy()
    X = df_ml[features]
    y = df_ml[target]

    # Handle categorical variables (One-Hot Encoding)
    X = pd.get_dummies(X, drop_first=True)

    # Split data (80% train, 20% test)
    # Using stratify=y to ensure the train/test sets have the same proportion of classes
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

    # Train a Decision Tree Classifier (Max Depth to prevent overfitting initially)
    # Using class_weight='balanced' to help with the low support of 'Excellent' and 'Fail' classes
    model = DecisionTreeClassifier(max_depth=5, random_state=42, class_weight='balanced')
    model.fit(X_train, y_train)

    # Predict and evaluate
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)

    # Generate classification report as a string
    report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)
    report_df = pd.DataFrame(report).transpose().round(2)
    report_str = report_df.to_markdown()

    # Get feature importance
    importance = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=False).head(10).round(4)

    return accuracy, report_str, importance


def main():
    # Header
    st.title("üìö Student Academic Performance Analyzer")
    st.markdown("""
    <div style='background-color: #282A36; padding: 20px; border-radius: 10px; margin-bottom: 20px;'>
        <h4>üìä Project Information</h4>
        <p><strong>Dataset:</strong> UCI Machine Learning Repository - Student Performance Dataset</p>
        <p><strong>Course:</strong> DAI011 - Programming for AI</p>
        <p><strong>Author:</strong> Drina Musiliüíï- 250636DAI</p>
        <p><strong>Purpose:</strong> Analyze factors affecting student academic performance in Mathematics</p>
    </div>
    """, unsafe_allow_html=True)

    st.sidebar.header("üìä About This Application")
    st.sidebar.info("""
        **This analyzer explores:**
        - üìà Grade distributions and statistics
        - ‚è∞ Study time impact on performance
        - üë• Gender-based comparisons
        - üß† **Machine Learning Prediction of Performance Category**

        **Dataset Details:**
        - 395 students from Portuguese schools
        - Math course performance data
        """)

    st.sidebar.markdown("---")
    st.sidebar.header("üõ†Ô∏è Technical Details")
    st.sidebar.markdown("""
        **Libraries Used:**
        - üêº Pandas, üî¢ NumPy, ü§ñ Scikit-learn
        - üìä Matplotlib, üé® Seaborn
        - üöÄ Streamlit - Web interface
        """)

    try:
        with st.spinner('Loading dataset...'):
            df = load_data()
        st.success(f"‚úÖ Dataset loaded successfully! ({df.shape[0]} students, {df.shape[1]} features)")
    except Exception as e:
        st.error(f"‚ùå Error loading data: {e}")
        st.stop()

    overall_stats = calculate_overall_stats(df)

    st.markdown("### üìä Key Metrics Overview")
    col1, col2, col3, col4, col5 = st.columns(5)

    with col1:
        st.metric("Total Students", df.shape[0])
    with col2:
        st.metric("Average Grade", f"{overall_stats['mean']:.2f}/20")
    with col3:
        st.metric("Pass Rate", f"{overall_stats['pass_rate']:.1f}%")
    with col4:
        st.metric("Median Grade", f"{overall_stats['median']:.1f}/20")
    with col5:
        st.metric("Std Deviation", f"{overall_stats['std']:.2f}")

    st.markdown("---")

    # ADDED 'üß† ML Prediction Model' tab
    tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
        "üìã Data Overview",
        "üìà Statistical Analysis",
        "üìä Visualizations",
        "üí° Key Insights",
        "üîç Data Explorer",
        "üß† ML Prediction Model"
    ])

    with tab1:
        st.header("üìã Dataset Overview")
        st.subheader("Sample Data (First 10 Rows)")
        st.dataframe(df.head(10), use_container_width=True, height=400)

        col1, col2 = st.columns(2)

        with col1:
            st.subheader("üìä Dataset Structure")
            st.write(f"**Total Rows:** {df.shape[0]}")
            st.write(f"**Total Columns:** {df.shape[1]}")
            # Corrected memory usage calculation
            st.write(f"**Memory Usage:** {df.memory_usage(deep=True).sum() / 1048576:.2f} MB")

            st.subheader("‚úÖ Data Quality")
            missing = df.isnull().sum().sum()
            if missing == 0:
                st.success("‚úÖ No missing values found - Clean dataset!")
            else:
                st.warning(f"‚ö†Ô∏è {missing} missing values detected")

            duplicates = df.duplicated().sum()
            if duplicates == 0:
                st.success("‚úÖ No duplicate rows found")
            else:
                st.warning(f"‚ö†Ô∏è {duplicates} duplicate rows detected")

        with col2:
            st.subheader("üìù Column Information")
            info_df = pd.DataFrame({
                'Column': df.columns[:15],
                'Type': df.dtypes[:15].astype(str),
                'Non-Null': df.count()[:15].values
            })
            st.dataframe(info_df, use_container_width=True, height=400)

        st.subheader("üìñ Key Features Description")
        col1_feat, col2_feat, col3_feat = st.columns(3)

        with col1_feat:
            st.markdown("""
            **Demographic Features:**
            - `age`: Student's age (15-22)
            - `sex`: Student's gender (F/M)
            - `address`: Home address type (U=urban, R=rural)
            - `famsize`: Family size (LE3 or GT3)
            """)

        with col2_feat:
            st.markdown("""
            **Academic Features:**
            - `studytime`: Weekly study time (1-4 scale)
            - `failures`: Number of past failures (0-4)
            - `absences`: Number of school absences
            - `G1, G2, G3`: Period grades (0-20)
            """)

        with col3_feat:
            st.markdown("""
            **Social Features:**
            - `famsup`: Family educational support (yes/no)
            - `activities`: Extra-curricular activities (yes/no)
            - `freetime`: Free time after school (1-5)
            - `goout`: Going out with friends (1-5)
            """)

    with tab2:
        st.header("üìà Statistical Analysis")

        st.subheader("1Ô∏è‚É£ Overall Grade Statistics")
        col1, col2, col3 = st.columns(3)

        with col1:
            st.metric("Mean Grade", f"{overall_stats['mean']:.2f}/20",
                     help="Average final grade across all students")
            st.metric("Median Grade", f"{overall_stats['median']:.2f}/20",
                     help="Middle value when grades are sorted")

        with col2:
            st.metric("Standard Deviation", f"{overall_stats['std']:.2f}",
                     help="Measure of grade variability")
            st.metric("Grade Range", f"{overall_stats['min']} - {overall_stats['max']}",
                     help="Minimum and maximum grades")

        with col3:
            st.metric("Pass Rate", f"{overall_stats['pass_rate']:.1f}%",
                     delta=f"{overall_stats['pass_rate'] - 50:.1f}% vs 50%",
                     delta_color="inverse",
                     help="Percentage of students with grade $\\ge 10$")
            st.metric("Fail Rate", f"{overall_stats['fail_rate']:.1f}%",
                     delta=f"{50 - overall_stats['fail_rate']:.1f}% vs 50%",
                     delta_color="inverse",
                     help="Percentage of students with grade $\\lt 10$")

        st.markdown("---")

        st.subheader("2Ô∏è‚É£ Performance Category Distribution")
        category_counts = df['performance_category'].value_counts()
        # SYNTAX ERROR FIXED HERE
        category_df = pd.DataFrame({
            'Category': category_counts.index,
            'Count': category_counts.values,
            'Percentage': (category_counts.values / len(df) * 100).round(1).astype(str) + '%'
        })
        st.dataframe(category_df.set_index('Category'))

        st.markdown("---")

        st.subheader("3Ô∏è‚É£ Performance by Key Categorical Factors")
        col_group1, col_group2, col_group3 = st.columns(3)

        with col_group1:
            st.caption("Sex")
            st.dataframe(analyze_by_category(df, 'sex'), use_container_width=True)

        with col_group2:
            st.caption("Family Support (`famsup`)")
            st.dataframe(analyze_by_category(df, 'famsup'), use_container_width=True)

        with col_group3:
            st.caption("Guardian")
            st.dataframe(analyze_by_category(df, 'guardian'), use_container_width=True)


    with tab3:
        st.header("üìä Data Visualizations")

        col_viz1, col_viz2 = st.columns(2)

        with col_viz1:
            st.subheader("Distribution of Final Grades (`G3`)")
            st.pyplot(plot_grade_distribution(df))

            st.subheader("Impact of Weekly Study Time")
            st.pyplot(plot_study_time_impact(df))

            st.subheader("Impact of Past Failures")
            st.pyplot(plot_failures_impact(df))


        with col_viz2:
            st.subheader("Overall Performance Category Distribution")
            st.pyplot(plot_performance_pie(df))

            st.subheader("Gender-Based Performance Comparison")
            st.pyplot(plot_gender_comparison(df))

            st.subheader("Family Support Impact")
            st.pyplot(plot_family_support(df))

        st.subheader("Feature Correlation Heatmap (Key Factors)")
        st.pyplot(plot_correlation_heatmap(df))

    with tab4:
        st.header("üí° Key Insights")
        st.markdown("""
        Based on the data analysis, here are the key factors influencing student performance:

        * **Previous Grades are Critical:** The strongest correlation with the final grade ($\text{G3}$) is the previous grade ($\text{G2}$), and the one before that ($\text{G1}$). This shows that performance is highly consistent.
        * **Past Failures are Detrimental:** There is a strong negative correlation between past failures and the final grade. Students with 1 or more past failures have significantly lower average grades.
        * **Study Time is Positive:** Students who report studying $5-10$ hours or more per week have the highest average grades, supporting the benefit of consistent effort.
        * **Class Imbalance:** The majority of students fall into the 'Pass' or 'Good' categories. The 'Excellent' ($\text{G3} \ge 17$) and 'Fail' ($\text{G3} < 10$) categories are minority classes, which presents a challenge for classification models.
        * **Gender:** On average, female students tend to have slightly higher final grades than male students.
        """)

    with tab5:
        st.header("üîç Data Explorer")
        st.markdown("Use the controls below to explore the data for a specific group of students.")

        col_filt1, col_filt2, col_filt3 = st.columns(3)

        with col_filt1:
            gender_filter = st.multiselect("Filter by Gender", df['sex'].unique(), default=df['sex'].unique())
            famsup_filter = st.multiselect("Filter by Family Support", df['famsup'].unique(), default=df['famsup'].unique())
        with col_filt2:
            studytime_filter = st.multiselect("Filter by Study Time", df['studytime'].unique(), default=df['studytime'].unique())
            age_min, age_max = int(df['age'].min()), int(df['age'].max())
            age_range = st.slider("Filter by Age", age_min, age_max, (age_min, age_max))
        with col_filt3:
            fail_min, fail_max = int(df['failures'].min()), int(df['failures'].max())
            fail_range = st.slider("Filter by Past Failures", fail_min, fail_max, (fail_min, fail_max))
            grade_min, grade_max = int(df['G3'].min()), int(df['G3'].max())
            grade_range = st.slider("Filter by Final Grade ($\text{G3}$)", grade_min, grade_max, (grade_min, grade_max))

        filtered_df = df[
            (df['sex'].isin(gender_filter)) &
            (df['famsup'].isin(famsup_filter)) &
            (df['studytime'].isin(studytime_filter)) &
            (df['age'] >= age_range[0]) & (df['age'] <= age_range[1]) &
            (df['failures'] >= fail_range[0]) & (df['failures'] <= fail_range[1]) &
            (df['G3'] >= grade_range[0]) & (df['G3'] <= grade_range[1])
        ]

        st.subheader(f"Filtered Data ({len(filtered_df)} students)")
        st.dataframe(filtered_df, use_container_width=True)

        if len(filtered_df) > 0:
            st.subheader("Filtered Group Grade Statistics")
            filtered_stats = calculate_overall_stats(filtered_df)
            col_fs1, col_fs2, col_fs3 = st.columns(3)
            with col_fs1:
                st.metric("Mean Grade", f"{filtered_stats['mean']:.2f}")
            with col_fs2:
                st.metric("Pass Rate", f"{filtered_stats['pass_rate']:.1f}%")
            with col_fs3:
                st.metric("Fail Rate", f"{filtered_stats['fail_rate']:.1f}%")


    with tab6:
        st.header("üß† ML Prediction Model")
        st.markdown("""
        This section uses a **Decision Tree Classifier** to predict a student's `performance_category` (Fail, Pass, Good, Excellent)
        based on their non-grade, social, and demographic factors.
        """)
        st.info("Note: $\\text{G1}$ and $\\text{G2}$ (previous grades) are intentionally excluded as features to test the predictive power of the other social/demographic factors.")

        try:
            with st.spinner('Training and evaluating model...'):
                accuracy, report_str, importance = perform_ml_analysis(df)

            st.subheader("Model Performance")
            st.metric("Classification Accuracy (on Test Set)", f"{accuracy*100:.2f}%")

            st.subheader("Detailed Classification Report")
            st.markdown(f"```markdown\n{report_str}\n```")

            st.markdown("""
            **Interpretation of Classification Report:**
            * **Precision:** Out of all students predicted as 'X', how many were actually 'X'?
            * **Recall:** Out of all students who were actually 'X', how many were predicted correctly?
            * **F1-Score:** The harmonic mean of Precision and Recall.
            * **Support:** The number of actual samples in the test set for that category.

            **Observation:** Predicting the 'Excellent' category (a minority class) is the hardest, often resulting in lower Precision and Recall scores.
            """)

            st.subheader("Top 10 Feature Importances")
            st.dataframe(importance)

        except Exception as e:
            st.error(f"‚ùå Error during ML analysis: {e}")


if __name__ == '__main__':
    main()
